{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "273c4ebb-76aa-41b5-8116-8c7d5afda039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "from datetime import datetime\n",
    "import json\n",
    "import argparse\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "cudnn.benchmark = True \n",
    "# fire on all cylinders \n",
    "import torchattacks\n",
    "import matplotlib.pyplot as plt\n",
    "from torch._utils import _accumulate\n",
    "from torch.utils.data import Subset, DataLoader, ConcatDataset\n",
    "import DataSets\n",
    "from DataSets import load_dataset_setting, MyBackdoorDataset\n",
    "print(torch.cuda.is_available())\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bff5dec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./raw_data/train_32x32.mat\n",
      "Using downloaded and verified file: ./raw_data/test_32x32.mat\n",
      "task,attack, TPR, TNR, ACC, F1\n",
      "svhn badnets 0.8055854333128457 0.30562384757221883 0.5556046404425323 0.3222391247560657\n",
      "Using downloaded and verified file: ./raw_data/train_32x32.mat\n",
      "Using downloaded and verified file: ./raw_data/test_32x32.mat\n",
      "task,attack, TPR, TNR, ACC, F1\n",
      "svhn blend 0.8069683466502766 0.3070067609096497 0.5569875537799631 0.3227922985909433\n",
      "Using downloaded and verified file: ./raw_data/train_32x32.mat\n",
      "Using downloaded and verified file: ./raw_data/test_32x32.mat\n",
      "task,attack, TPR, TNR, ACC, F1\n",
      "svhn nature 0.8069683466502766 0.3070067609096497 0.5569875537799631 0.3227922985909433\n",
      "Using downloaded and verified file: ./raw_data/train_32x32.mat\n",
      "Using downloaded and verified file: ./raw_data/test_32x32.mat\n",
      "task,attack, TPR, TNR, ACC, F1\n",
      "svhn trojan_sq 0.8069683466502766 0.3070067609096497 0.5569875537799631 0.3227922985909433\n",
      "Using downloaded and verified file: ./raw_data/train_32x32.mat\n",
      "Using downloaded and verified file: ./raw_data/test_32x32.mat\n",
      "task,attack, TPR, TNR, ACC, F1\n",
      "svhn trojan_wm 0.8067378610940381 0.3067762753534112 0.5567570682237246 0.3227001029517971\n",
      "Using downloaded and verified file: ./raw_data/train_32x32.mat\n",
      "Using downloaded and verified file: ./raw_data/test_32x32.mat\n",
      "task,attack, TPR, TNR, ACC, F1\n",
      "svhn l2_inv 0.8065073755377996 0.30654578979717273 0.5565265826674861 0.32260790731265077\n",
      "| Wide-Resnet 22x10\n",
      "task,attack, TPR, TNR, ACC, F1\n",
      "flower badnets 0.7480392156862745 0.2980392156862745 0.5230392156862745 0.30532212885154064\n",
      "| Wide-Resnet 22x10\n",
      "task,attack, TPR, TNR, ACC, F1\n",
      "flower blend 0.7470588235294118 0.29705882352941176 0.5220588235294118 0.304921968787515\n",
      "| Wide-Resnet 22x10\n",
      "task,attack, TPR, TNR, ACC, F1\n",
      "flower nature 0.7470588235294118 0.29705882352941176 0.5220588235294118 0.304921968787515\n",
      "| Wide-Resnet 22x10\n",
      "task,attack, TPR, TNR, ACC, F1\n",
      "flower trojan_sq 0.7470588235294118 0.29705882352941176 0.5220588235294118 0.304921968787515\n",
      "| Wide-Resnet 22x10\n",
      "task,attack, TPR, TNR, ACC, F1\n",
      "flower trojan_wm 0.7470588235294118 0.29705882352941176 0.5220588235294118 0.304921968787515\n",
      "| Wide-Resnet 22x10\n",
      "task,attack, TPR, TNR, ACC, F1\n",
      "flower l2_inv 0.7480392156862745 0.2980392156862745 0.5230392156862745 0.30532212885154064\n"
     ]
    }
   ],
   "source": [
    "from art.defences.detector.poison import SpectralSignatureDefense, ActivationDefence\n",
    "from art.estimators.classification.pytorch import PyTorchClassifier\n",
    "import json\n",
    "#task,backdoor_name,targetclass,4,prefix\n",
    "def spectral_sign_AC(task,attackname,targetclass, trigger_size=4, prefifix='',defense= '',**kwargs):\n",
    "    '''\n",
    "        task: dataset name ['cifar10','mnist', 'cifar100']\n",
    "        \n",
    "    '''\n",
    "    # \n",
    "    \n",
    "        \n",
    "    BATCH_SIZE, N_EPOCH, trainset, testset,  Model, class_num = load_dataset_setting(task)\n",
    "    \n",
    "    testset_mal = MyBackdoorDataset(testset,targetclass,1, p_size=trigger_size,attack_names=[attackname],mal_only=True)\n",
    "    test_mal_x=testset_mal.all_trojan()\n",
    "    testset_x=torch.cat([torch.unsqueeze(xy[0],dim=0) for xy in testset],dim=0).numpy()\n",
    "    \n",
    "    test_all = np.concatenate([testset_x,test_mal_x], axis = 0)\n",
    "    \n",
    "    y_clean=[xy[1] for xy in testset]\n",
    "    y_test_all=np.array(y_clean+[targetclass]*len(test_mal_x))\n",
    "    \n",
    "    \n",
    "    save_path = './my_models/original_trajoned_%s_targetclass_%s_%s.model'%(attackname,str(targetclass),task)\n",
    "    \n",
    "    model=Model(num_class=class_num)\n",
    "    model.load_state_dict(torch.load(save_path))\n",
    "    loss= F.cross_entropy\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.9, weight_decay=0.0005)\n",
    "     \n",
    "    p_classifier =  PyTorchClassifier(model, loss, (3,32,32), class_num, optimizer)\n",
    "    \n",
    "    \n",
    "    N=len(testset)\n",
    "    \n",
    "   \n",
    "    is_clean = np.array([1]*N+[0]*N)\n",
    "    if defense==\"SpecSig\":\n",
    "        Spec=SpectralSignatureDefense(p_classifier, test_all, y_test_all, \n",
    "                                      expected_pp_poison=0.5,batch_size=BATCH_SIZE)\n",
    "\n",
    "        conf_matrix= Spec.evaluate_defence(is_clean)\n",
    "    else:\n",
    "        #kwargs = {\"reduce\":reduce , \"analysis\": analysis, \"nb_dim\": nb_d}\n",
    "        print( kwargs)         \n",
    "        AC=ActivationDefence(p_classifier, test_all, y_test_all)\n",
    "        AC.detect_poison(nb_dims=kwargs[\"nb_dim\"],reduce=  kwargs[\"reduce\"],\n",
    "                      cluster_analysis= kwargs[\"analysis\"], nb_clusters=2)\n",
    "        conf_matrix= AC.evaluate_defence(is_clean)\n",
    "        #     defence_params = [\n",
    "        #     \"nb_clusters\",\n",
    "        #     \"clustering_method\",\n",
    "        #     \"nb_dims\",\n",
    "        #     \"reduce\",\n",
    "        #     \"cluster_analysis\",\n",
    "        #     \"generator\",\n",
    "        #     \"ex_re_threshold\",\n",
    "        # ]\n",
    "        # valid_clustering = [\"KMeans\"]\n",
    "        # valid_reduce = [\"PCA\", \"FastICA\", \"TSNE\"]\n",
    "        # valid_analysis = [\"smaller\", \"distance\", \"relative-size\", \"silhouette-scores\"]\n",
    "        # reduce (str) – method used to reduce dimensionality of the activations. \n",
    "#               Supported methods include PCA, FastICA and TSNE\n",
    "# nb_dims (int) – number of dimensions to be reduced\n",
    "# cluster_analysis (str) – heuristic to automatically determine if a cluster contains poisonous data.\n",
    "#                         Supported methods include smaller and distance. \n",
    "#                         The smaller method defines as poisonous the cluster with less number of\n",
    "#                         data points, while the distance heuristic uses the distance between \n",
    "#                         the clusters.\n",
    "    return conf_matrix\n",
    "    \n",
    "\n",
    "def read_conf_matrix(conf_matrix):\n",
    "    \n",
    "    TP, TN, FP, FN=0,0,0,0\n",
    "    N_TP, N_TN=0,0\n",
    "    for cl,key in enumerate(conf_matrix.keys()):\n",
    "        dict_info=conf_matrix[key]\n",
    "        TP += int(dict_info[\"TruePositive\"][\"numerator\"])\n",
    "        TN += int(dict_info[\"TrueNegative\"][\"numerator\"])\n",
    "        FP += int(dict_info[\"FalsePositive\"][\"numerator\"])\n",
    "        FN += int(dict_info[\"FalseNegative\"][\"numerator\"])\n",
    "        N_TP +=  dict_info[\"TruePositive\"][\"denominator\"]\n",
    "        N_TN +=  dict_info[\"TrueNegative\"][\"denominator\"]\n",
    "        \n",
    "    TPR= TP/ N_TP\n",
    "    TNR = TN/ N_TN\n",
    "    F1= TP/(2*TP+FN+FP)  \n",
    "    return TPR, TNR, F1\n",
    "    \n",
    "prefix=''\n",
    "defenses=['SpecSig', 'ActivationClustering']#'ActivationClustering'\n",
    "\n",
    "valid_reduce = [\"FastICA\", \"PCA\"]\n",
    "valid_analysis = [\"smaller\", \"distance\"]\n",
    "nb_dims = [2,10]\n",
    "dict_spect={'task':[],'backdoor_name':[], 'TPR':[], 'TNR':[], 'ACC':[], 'F1':[], 'hyperParam':[]}\n",
    "\n",
    "defense= \"SpecSig\" #s'ActivationClustering'\n",
    "\n",
    "for task in ['svhn','flower']:# 'cifar10','cifar100','gtsrb','svhn',\n",
    "\n",
    "    for backdoor_name in [ 'badnets','blend','nature','trojan_sq','trojan_wm', 'l2_inv'  ]:#,'natural_'+task\n",
    "        targetclass = 6 \n",
    "        if defense == \"SpecSig\":\n",
    "            conf_mat = spectral_sign_AC(task,backdoor_name,targetclass,4,\n",
    "                                        prefix,defense= defense)\n",
    "            conf_mat = json.loads(conf_mat)\n",
    "            TPR, TNR, F1 = read_conf_matrix(conf_mat)\n",
    "            dict_spect[\"task\"].append(task)\n",
    "            dict_spect[\"backdoor_name\"].append(backdoor_name)\n",
    "            dict_spect[\"TPR\"].append(TPR)\n",
    "            dict_spect[\"TNR\"].append(TNR)\n",
    "            dict_spect[\"ACC\"].append((TPR+ TNR)/2)\n",
    "            dict_spect[\"F1\"].append(F1)\n",
    "            print(\"task,attack, TPR, TNR, ACC, F1\")\n",
    "            print(task, backdoor_name, TPR, TNR , (TPR+ TNR)/2, F1)\n",
    "        else: \n",
    "            for reduce in valid_reduce:\n",
    "                for analysis  in valid_analysis:\n",
    "                    for nb_d in nb_dims:\n",
    "                        kwargs = {\"reduce\":reduce , \"analysis\": analysis, \"nb_dim\": nb_d}\n",
    "                        dict_spect['hyperParam'].append([reduce,analysis,nb_d])\n",
    "                        conf_mat = spectral_sign_AC(task,backdoor_name,targetclass,4,\n",
    "                                                    prefix,defense= defense, nb_dim=nb_d,\n",
    "                                                   reduce=reduce , analysis=analysis)\n",
    "        \n",
    "                        conf_mat = json.loads(conf_mat)\n",
    "                        TPR, TNR, F1 = read_conf_matrix(conf_mat)\n",
    "                        dict_spect[\"task\"].append(task)\n",
    "                        dict_spect[\"backdoor_name\"].append(backdoor_name)\n",
    "                        dict_spect[\"TPR\"].append(TPR)\n",
    "                        dict_spect[\"TNR\"].append(TNR)\n",
    "                        dict_spect[\"ACC\"].append((TPR+ TNR)/2)\n",
    "                        dict_spect[\"F1\"].append(F1)\n",
    "                        print(\"nb_dims,analysis,reduce,task,attack, TPR, TNR, ACC, F1\")\n",
    "        \n",
    "                        print(nb_d,analysis,reduce,\n",
    "                              task, backdoor_name, TPR, TNR , (TPR+ TNR)/2, F1)\n",
    "    np.save('results/%s_%s_res.npy'%(defense,task), dict_spect)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61a74bed-581d-4f9f-b8c2-41142d0f02cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cifar100 badnets TPR/TNR:4.76/18.28  Acc:0.4324 F1: 0.0387\n",
      "cifar100 blend TPR/TNR:0.01/38.88  Acc:0.3056 F1: 0.0001\n",
      "cifar100 nature TPR/TNR:31.20/19.81  Acc:0.5569 F1: 0.2066\n",
      "cifar100 trojan_sq TPR/TNR:27.47/16.48  Acc:0.5550 F1: 0.1908\n",
      "cifar100 trojan_wm TPR/TNR:42.01/19.05  Acc:0.6148 F1: 0.2608\n",
      "cifar100 l2_inv TPR/TNR:0.01/36.50  Acc:0.3175 F1: 0.0001\n",
      "------------------------------\n",
      "cifar10 badnets TPR/TNR:100.00/87.43  Acc:0.5628 F1: 0.3479\n",
      "cifar10 blend TPR/TNR:100.00/82.40  Acc:0.5880 F1: 0.3541\n",
      "cifar10 nature TPR/TNR:100.00/88.60  Acc:0.5570 F1: 0.3465\n",
      "cifar10 trojan_sq TPR/TNR:100.00/82.90  Acc:0.5855 F1: 0.3535\n",
      "cifar10 trojan_wm TPR/TNR:0.03/44.10  Acc:0.2797 F1: 0.0002\n",
      "cifar10 l2_inv TPR/TNR:100.00/76.70  Acc:0.6165 F1: 0.3614\n",
      "------------------------------\n",
      "gtsrb badnets TPR/TNR:100.00/89.97  Acc:0.5502 F1: 0.3449\n",
      "gtsrb blend TPR/TNR:100.00/98.69  Acc:0.5066 F1: 0.3348\n",
      "gtsrb nature TPR/TNR:100.00/99.05  Acc:0.5048 F1: 0.3344\n",
      "gtsrb trojan_sq TPR/TNR:100.00/94.92  Acc:0.5254 F1: 0.3391\n",
      "gtsrb trojan_wm TPR/TNR:100.00/99.05  Acc:0.5048 F1: 0.3344\n",
      "gtsrb l2_inv TPR/TNR:100.00/92.07  Acc:0.5397 F1: 0.3424\n",
      "------------------------------\n",
      "svhn badnets TPR/TNR:100.00/74.70  Acc:0.6265 F1: 0.3640\n",
      "svhn blend TPR/TNR:18.20/45.52  Acc:0.3634 F1: 0.1111\n",
      "svhn nature TPR/TNR:4.82/7.59  Acc:0.4862 F1: 0.0429\n",
      "svhn trojan_sq TPR/TNR:6.89/7.59  Acc:0.4965 F1: 0.0602\n",
      "svhn trojan_wm TPR/TNR:5.21/7.47  Acc:0.4887 F1: 0.0462\n",
      "svhn l2_inv TPR/TNR:23.29/46.93  Acc:0.3818 F1: 0.1368\n",
      "------------------------------\n",
      "flower badnets TPR/TNR:100.00/88.04  Acc:0.5598 F1: 0.3472\n",
      "flower blend TPR/TNR:100.00/84.51  Acc:0.5775 F1: 0.3515\n",
      "flower nature TPR/TNR:100.00/19.22  Acc:0.9039 F1: 0.4562\n",
      "flower trojan_sq TPR/TNR:100.00/85.69  Acc:0.5716 F1: 0.3500\n",
      "flower trojan_wm TPR/TNR:100.00/84.12  Acc:0.5794 F1: 0.3520\n",
      "flower l2_inv TPR/TNR:100.00/87.84  Acc:0.5608 F1: 0.3474\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#\n",
    "df = pd.read_csv('./results/ActivationClustering.csv')\n",
    "# df = pd.read_csv('./results/SpectralSigniture.csv')\n",
    "\n",
    "for task in ['cifar100','cifar10','gtsrb','svhn','flower']:\n",
    "    for backdoor_name in [ 'badnets','blend','nature','trojan_sq','trojan_wm', 'l2_inv' ]:\n",
    "        df2=df[(df['task']==task) & (df['backdoor_name']==backdoor_name)]\n",
    "        l=np.array(df2['ACC'])\n",
    "        l2=np.array(df2['F1'])\n",
    "        l3=np.array(df2['TPR'])\n",
    "        l4=np.array(df2['TNR'])\n",
    "        ind= np.argmax(l2)\n",
    "        # ind=0\n",
    "        \n",
    "        print(task, backdoor_name, 'TPR/TNR:%.2f/%.2f  Acc:%.4f F1: %.4f'%(l3[ind]*100,100-l4[ind]*100, l[ind], l2[ind]))\n",
    "    print('---'*10)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe745bc-a91f-4dc8-8813-0f92533ea75c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9af261d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#https://github.com/ndb796/Pytorch-Adversarial-Training-CIFAR/blob/e0a5218aee190381577f4067bf71939de1b69f66/interpolated_adversarial_training.py#L40\n",
    "\n",
    "class LinfPGDAttack(object):\n",
    "    def __init__(self, model,alpha=0.00784,epsilon= 0.0314):\n",
    "        self.model = model\n",
    "        self.alpha=  alpha\n",
    "        self.epsilon=  epsilon\n",
    "        \n",
    "    def perturb(self, x_natural, y):\n",
    "        x = x_natural.detach()\n",
    "        x = x + torch.zeros_like(x).uniform_(-self.epsilon, self.epsilon)\n",
    "        for i in range(100):\n",
    "            x.requires_grad_()\n",
    "            with torch.enable_grad():\n",
    "                logits = self.model(x)\n",
    "                loss = F.cross_entropy(logits, y)\n",
    "            grad = torch.autograd.grad(loss, x)[0]\n",
    "            x = x.detach() + self.alpha * torch.sign(grad.detach())\n",
    "            x = torch.min(torch.max(x, x_natural - self.epsilon), x_natural + self.epsilon)\n",
    "            x = torch.clamp(x, 0, 1)\n",
    "        return x\n",
    "\n",
    "\n",
    "def train_model(model, dataloader, epoch_num, gpu=True,verbose=True, Robustness=False, epsilon=None):\n",
    "    '''\n",
    "    model: initial model \n",
    "    dataloader: Dataloader pytirch dataset\n",
    "    epoch_num : numebr of epochs for training \n",
    "    '''\n",
    "    \n",
    "    model.train()\n",
    "    learning_rate = 0.1\n",
    "    weight_decay = 1e-4\n",
    "    \n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.9, weight_decay=weight_decay)\n",
    "        \n",
    "    for epoch in range(epoch_num):\n",
    "        \n",
    "        cum_loss = 0.0\n",
    "        cum_acc = 0.0\n",
    "        tot = 0.0\n",
    "        for i,(x_in, y_in) in enumerate(dataloader):\n",
    "            if gpu:\n",
    "                x_in,y_in=x_in.cuda(),y_in.cuda()\n",
    "            \n",
    "            B = x_in.size()[0]\n",
    "            pred = model(x_in)\n",
    "\n",
    "            loss = model.loss(pred, y_in)\n",
    "            if Robustness:\n",
    "                if epsilon != None:\n",
    "                    adversary=LinfPGDAttack(model,epsilon=epsilon)\n",
    "                else:\n",
    "                    adversary=LinfPGDAttack(model)\n",
    "                adv=adversary.perturb(x_in,y_in)\n",
    "                pred = model(adv)\n",
    "                loss+=model.loss(pred, y_in)\n",
    "                \n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            \n",
    "            cum_loss += loss.item() * B\n",
    "            \n",
    "            pred_c = pred.max(1)[1].cpu()\n",
    "            cum_acc += (pred_c.eq(y_in.cpu())).sum().item()\n",
    "            tot = tot + B\n",
    "        if verbose:\n",
    "            print (\"Epoch %d, loss = %.4f, acc = %.4f\"%(epoch, cum_loss/tot, cum_acc/tot))\n",
    "    return\n",
    "\n",
    "# Train a Model without Trigger--> Clean Model\n",
    "def train_naive_Model(task, TrainanyWay=False):\n",
    "    \n",
    "    BATCH_SIZE, N_EPOCH, trainset, testset,  Model, class_num = load_dataset_setting(task)\n",
    "    tot_num = len(trainset)\n",
    "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(testset, batch_size=1)\n",
    "    if not os.path.exists('./my_models'):\n",
    "        os.mkdir('./my_models')\n",
    "        \n",
    "    # Learning two clean model one will be used for training the discriminator and one for testing the disriminator\n",
    "    save_path = './my_models/naive_%s.model'%task\n",
    "    gpu=False\n",
    "    model=Model(num_class=class_num)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        gpu=True\n",
    "        model=Model(gpu=gpu,num_class=class_num)\n",
    "        model=model.cuda()\n",
    "    if not os.path.exists(save_path) or TrainanyWay:\n",
    "        train_model(model, train_loader, epoch_num=N_EPOCH,gpu=gpu, verbose=True)\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "    else:\n",
    "        model.load_state_dict(torch.load(save_path))\n",
    "        \n",
    "\n",
    "    acc = eval_model(model, test_loader,gpu=gpu)\n",
    "    return acc\n",
    "    print (\"Acc of naive model is %.4f, saved to %s @ %s\"%(acc, save_path, datetime.now()))\n",
    "        \n",
    "# Train a Trojan Model with Trigger withput MinMax or Distilation--> Traditional Learning of Trojans\n",
    "def train_traditional_backdoor_Model(task,p, targetclass,attackname, trigger_size=4,TrainanyWay=False,Robustness=False, epsilon=None):\n",
    "    '''\n",
    "        p:  Percentage of datasets that is poisoned\n",
    "        task: dataset name ['cifar10','mnist', 'cifar100']\n",
    "        TrainanyWay: if it false and the model was already trained then it does not train the model again\n",
    "    '''\n",
    "    # \n",
    "    if not os.path.exists('./my_models'):\n",
    "        os.mkdir('./my_models')\n",
    "        \n",
    "    BATCH_SIZE, N_EPOCH, trainset, testset,  Model, class_num = load_dataset_setting(task)\n",
    "    tot_num = len(trainset)\n",
    "    if Robustness: N_EPOCH=10\n",
    "    #self, src_dataset,targetclass,inject_p=0.08,p_size=4,mal_only=False\n",
    "\n",
    "    trainset_mal = MyBackdoorDataset(trainset,targetclass,p,p_size=trigger_size,attack_names=[attackname])\n",
    "    testset_mal = MyBackdoorDataset(testset,targetclass,p, p_size=trigger_size,attack_names=[attackname],mal_only=True)\n",
    "\n",
    "    train_loader_mal = torch.utils.data.DataLoader(trainset_mal, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    test_loader_clean = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE)\n",
    "    test_loader_mal = torch.utils.data.DataLoader(testset_mal, batch_size=BATCH_SIZE)\n",
    "\n",
    "    if Robustness:\n",
    "        save_path = './my_models/robust_eps_%.4f_original_trajoned_%s_targetclass_%s_%s.model'%(epsilon,attackname,str(targetclass),task)\n",
    "    else:\n",
    "        save_path = './my_models/original_trajoned_%s_targetclass_%s_%s.model'%(attackname,str(targetclass),task)\n",
    "        \n",
    "    gpu=False\n",
    "    model=Model(gpu=gpu,num_class=class_num)\n",
    "    if torch.cuda.is_available():\n",
    "        gpu=True\n",
    "        model=Model(gpu=gpu,num_class=class_num)\n",
    "        model=model.cuda()\n",
    "\n",
    "    \n",
    "    if not os.path.exists(save_path) or TrainanyWay:\n",
    "        print(save_path)\n",
    "        train_model(model, train_loader_mal, epoch_num=N_EPOCH,verbose=True,Robustness=Robustness, epsilon=epsilon)\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "    else:\n",
    "        model.load_state_dict(torch.load(save_path))\n",
    "    \n",
    "    acc_back = eval_model(model, test_loader_mal)\n",
    "    acc = eval_model(model, test_loader_clean)\n",
    "    return acc, acc_back\n",
    "    print (\"Acc of the model is %.4f on clean images and %.4f on images with backdoors, saved to %s @ %s\"%(acc,acc_back, save_path, datetime.now()))\n",
    "\n",
    "def eval_model(model, dataloader, gpu=True):\n",
    "    model.eval()\n",
    "    cum_acc = 0.0\n",
    "    tot = 0.0\n",
    "    for i,(x_in, y_in) in enumerate(dataloader):\n",
    "        B = x_in.size()[0]\n",
    "        if gpu:\n",
    "            x_in=x_in.cuda()\n",
    "        pred = model(x_in)\n",
    "        \n",
    "        pred_c = pred.max(1)[1].cpu()\n",
    "        cum_acc += (pred_c.eq(y_in)).sum().item()\n",
    "        tot = tot + B\n",
    "    return cum_acc / tot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42662f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "       \n",
    "        \n",
    "def adversarial_learning(model,data,y, attack_type,nb_classes,Targeted=False):\n",
    "\n",
    "    hyper_param=None\n",
    "    flag_mis=False\n",
    "    input_shape = data.shape[1:]\n",
    "    if attack_type=='FGSM':\n",
    "        epsilon = np.arange(0.001,2,0.001)\n",
    "       \n",
    "        \n",
    "        for eps in epsilon:\n",
    "            atk= torchattacks.FGSM(model, eps=eps)\n",
    "            adv_images = atk(data, y)\n",
    "            pred=model.forward(adv_images)\n",
    "            if not (y== pred.max(1)[1].cpu()):\n",
    "                flag_mis=True\n",
    "                hyper_param=eps\n",
    "                break\n",
    "        \n",
    "    elif attack_type=='IFGSM':\n",
    "   \n",
    "        atk= torchattacks.FGSM(model, eps=0.0001)\n",
    "        adv_images=data.clone().detach().cuda()\n",
    "        for i in range(10000):\n",
    "            adv_images = atk(adv_images, y)\n",
    "            pred=model.forward(adv_images)\n",
    "            if not (y== pred.max(1)[1].cpu()):\n",
    "                flag_mis=True\n",
    "                break\n",
    "    elif attack_type== 'DeepFool':\n",
    "        overshoot=np.arange(0.0001,10,0.0002)\n",
    "        for ov in overshoot:\n",
    "            atk=torchattacks.DeepFool(model, steps=250, overshoot=ov)\n",
    "            adv_images = atk(data, y)\n",
    "            pred=model.forward(adv_images)\n",
    "            if not (y== pred.max(1)[1].cpu()):\n",
    "                flag_mis=True\n",
    "                hyper_param=ov\n",
    "                break\n",
    "                \n",
    "    elif attack_type=='CW':\n",
    "        CWs=np.arange(0.0001,10,0.0002)\n",
    "        for c_cw in CWs:\n",
    "            atk= torchattacks.CW(model, c=c_cw,kappa=50, steps=250)\n",
    "            adv_images = atk(data, y)\n",
    "            pred=model.forward(adv_images)\n",
    "            \n",
    "            if not (y== pred.max(1)[1].cpu()):\n",
    "                flag_mis=True\n",
    "                hyper_param=c_cw\n",
    "                break\n",
    "    elif attack_type == 'blackbox2':\n",
    "        adv_images,sigma=guassian_noise(model,data,y)\n",
    "        pred=model.forward(adv_images)\n",
    "        if not (y== pred.max(1)[1].cpu()):\n",
    "            flag_mis=True\n",
    "            hyper_param=sigma\n",
    "    elif attack_type == 'blackbox':\n",
    "        \"\"\"\n",
    "          max_iter: int = 50,\n",
    "        max_eval: int = 10000,\n",
    "        init_eval: int = 100,\n",
    "        init_size: int = 100,\n",
    "        Create a HopSkipJump attack instance.\n",
    "        :param classifier: A trained classifier.\n",
    "        :param batch_size: The size of the batch used by the estimator during inference.\n",
    "        :param targeted: Should the attack target one specific class.\n",
    "        :param norm: Order of the norm. Possible values: \"inf\", np.inf or 2.\n",
    "        :param max_iter: Maximum number of iterations.\n",
    "        :param max_eval: Maximum number of evaluations for estimating gradient.\n",
    "        :param init_eval: Initial number of evaluations for estimating gradient.\n",
    "        :param init_size: Maximum number of trials for initial generation of adversarial examples.\n",
    "        :param verbose: Show progress bars.\n",
    "        \"\"\"\n",
    "\n",
    "        from art.attacks.evasion import HopSkipJump\n",
    "        from art.estimators.classification import PyTorchClassifier\n",
    "        import torch.nn as nn\n",
    "        import torch.nn.functional as F\n",
    "        import torch.optim as optim\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "        classifier = PyTorchClassifier(model=model,loss=criterion, optimizer=optimizer,\n",
    "            input_shape=input_shape,nb_classes=nb_classes, clip_values=(0, 1))\n",
    "        adv_crafter = HopSkipJump(classifier,batch_size=len(data),init_eval=10,\n",
    "            init_size=100,max_iter=20,max_eval=1000,verbose=False)\n",
    "        adv_images= adv_crafter.generate(data.detach().cpu().numpy())\n",
    "        adv_images=torch.from_numpy(adv_images).cuda()\n",
    "\n",
    "        pred=model(adv_images)\n",
    "        pred= pred.max(1)[1].cpu()\n",
    "        flag_mis=False if pred==y else True\n",
    "\n",
    "\n",
    "    elif attack_type == 'guassian_noise':\n",
    "        flag_mis=False\n",
    "        for sigma in np.arange(0.0001,0.0025,0.0001):\n",
    "            noise=torch.normal(0, sigma, size=(100, data.shape[1], data.shape[2], data.shape[3])).cuda()\n",
    "            x = torch.clip(data + noise, 0,1)\n",
    "            pred=model(x)\n",
    "            pred= pred.max(1)[1].cpu()\n",
    "            idx=[i for i,p in enumerate(pred) if p.cpu()==y.cpu()]\n",
    "            if len(idx)>0:\n",
    "                delta=[np.sqrt(np.sum(np.square(n.detach().cpu().numpy()))) for n in noise]\n",
    "                i=np.argmin(np.array(delta))\n",
    "                adv_images=torch.clip(data+noise[i:i+1],0,1)\n",
    "                \n",
    "                hyper_param=sigma\n",
    "                flag_mis=True\n",
    "                    \n",
    "\n",
    "\n",
    "    if not flag_mis:\n",
    "        adv_images=data\n",
    "    \n",
    "    return adv_images, flag_mis, hyper_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "776c94d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RobustnessAnalysys(task,attack,targetclass,trigger_size,backdoor_name,prefix=''):\n",
    "    print('Here'*10)\n",
    "    if not os.path.exists('./results'):\n",
    "        os.mkdir('./results')\n",
    "    if os.path.exists('./results/%s%s_%s_%s.npy'%(prefix,attack,task,backdoor_name)):\n",
    "        print( 'The attack of %s for the task of %s already exists '%(attack, task) )\n",
    "        return 0\n",
    "    \n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    BATCH_SIZE, N_EPOCH, trainset, testset,  Model, class_num = load_dataset_setting(task)\n",
    "    tot_num = len(trainset)\n",
    "    \n",
    "    if task=='cifar100' or task=='flower': testset=trainset\n",
    "\n",
    "    testset_mal = MyBackdoorDataset(testset,targetclass,1, p_size=trigger_size,mal_only=True,attack_names=[backdoor_name])\n",
    "    test_loader_clean = torch.utils.data.DataLoader(testset, batch_size=1,shuffle=True)\n",
    "    test_loader_mal = torch.utils.data.DataLoader(testset_mal, batch_size=1,shuffle=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if 'natural' in backdoor_name:\n",
    "        save_path = './my_models/naive_%s.model'%task\n",
    "    else:\n",
    "        save_path = './my_models/%soriginal_trajoned_%s_targetclass_%s_%s.model'%(prefix,backdoor_name,str(targetclass),task)\n",
    "    print('loading ...\\n'+save_path)\n",
    "    \n",
    "    \n",
    "    model=Model(gpu=True,num_class=class_num)\n",
    "    model=model.cuda()\n",
    "    model.load_state_dict(torch.load(save_path))\n",
    "    model = model.eval()\n",
    "    \n",
    "    \n",
    "    \n",
    "    N=1000\n",
    "    dict_adv={'data':[], 'adv':[],'Trojaned':[], 'features':[],  'true_y':[], 'delta':[], 'hyperP':[], 'success':[] }\n",
    "    \n",
    "    total=0\n",
    "    for data,y in test_loader_mal:\n",
    "        data=data.cuda()\n",
    "        pred=model.forward(data)\n",
    "        if total%50==0 and total<N:\n",
    "            print(total)\n",
    "        \n",
    "        if total>=N: break\n",
    "        flag_mis=False\n",
    "        if y== pred.max(1)[1].cpu()  and total<N:\n",
    "            dict_adv['Trojaned'].append(1)\n",
    "            total+=1\n",
    "            adv_images, flag_mis, hyper_param=adversarial_learning(model,data,y,attack,class_num, Targeted=False)\n",
    "            dict_adv['hyperP'].append(hyper_param)\n",
    "            dict_adv['features'].append([model.FeatureExtraction(data).detach().cpu().numpy()])\n",
    "            if not flag_mis:\n",
    "                dict_adv['adv'].append(data.detach().cpu())\n",
    "                dict_adv['delta'].append(None)\n",
    "                dict_adv['features'][-1].append([])\n",
    "                dict_adv['success'].append(0)\n",
    "            else:\n",
    "                dict_adv['adv'].append(adv_images.detach().cpu())\n",
    "                dict_adv['success'].append(1)\n",
    "                dict_adv['features'][-1].append(model.FeatureExtraction(adv_images).detach().cpu().numpy())\n",
    "                a,b=data.detach().cpu().numpy().squeeze(), adv_images.detach().cpu().numpy()\n",
    "                dict_adv['delta'].append(np.sqrt(np.sum(np.square(a-b))))\n",
    "        \n",
    "    total=0\n",
    "    for data,y in test_loader_clean:\n",
    "        if total>=N: break\n",
    "        \n",
    "        data=data.cuda()\n",
    "        pred=model.forward(data)\n",
    "        \n",
    "        if total%50==0 and total<N:\n",
    "            print(total)\n",
    "        \n",
    "        if y== pred.max(1)[1].cpu()  and total<N:\n",
    "            dict_adv['Trojaned'].append(0)\n",
    "            total+=1\n",
    "            #adversarial_learning(model,data,y, attack_type,nb_classes,Targeted=False)\n",
    "            adv_images, flag_mis, hyper_param=adversarial_learning(model,data,y,attack,class_num, Targeted=False)\n",
    "            dict_adv['hyperP'].append(hyper_param)\n",
    "            dict_adv['features'].append([model.FeatureExtraction(data).detach().cpu().numpy()])\n",
    "            if not flag_mis:\n",
    "                dict_adv['adv'].append(data.detach().cpu())\n",
    "                dict_adv['delta'].append(None)\n",
    "                dict_adv['features'][-1].append([])\n",
    "                dict_adv['success'].append(0)\n",
    "            else:\n",
    "                dict_adv['success'].append(1)\n",
    "                dict_adv['adv'].append(adv_images.detach().cpu())\n",
    "                dict_adv['features'][-1].append(model.FeatureExtraction(adv_images).detach().cpu().numpy())\n",
    "                a,b=data.detach().cpu().numpy().squeeze(), adv_images.detach().cpu().numpy()\n",
    "                dict_adv['delta'].append(np.sqrt(np.sum(np.square(a-b))))\n",
    "\n",
    "    \n",
    "\n",
    "    #############################################\n",
    "\n",
    "    print('*'*30)\n",
    "    a=[i for i in dict_adv['delta'][:N] if i is not None]\n",
    "    b=[i for i in dict_adv['delta'][N:] if i is not None]\n",
    "    print('Delta values Average for clean and Trojan Samples:', np.mean(a), np.mean(b))\n",
    "    print('Average Success Rate for clean and Trojan Samples:', np.sum(dict_adv['success'][:N])/N, np.sum(dict_adv['success'][N:])/N)\n",
    "    np.save('./results/%s%s_%s_%s.npy'%(prefix,attack,task,backdoor_name),dict_adv)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "def STRIP(task,trigger_size,backdoor_name,targetclass,prefix=''):\n",
    "    N=1000\n",
    "\n",
    "    def test_model(model,x,y,test_samples):\n",
    "        succ=0\n",
    "\n",
    "        test_samples=torch.stack(test_samples).cuda()\n",
    "\n",
    "        temp= (x+test_samples )/2\n",
    "        pred=model(temp)\n",
    "        pred=pred.max(1)[1].cpu()\n",
    "        succ=np.sum([1 for i in range(len(pred)) if y==pred[i]])\n",
    "\n",
    "        return succ/len(test_samples)\n",
    "\n",
    "    \n",
    "    BATCH_SIZE, N_EPOCH, trainset, testset,  Model, class_num = load_dataset_setting(task)\n",
    "    \n",
    "    idx=np.random.choice( len(trainset),20)\n",
    "\n",
    "    test_samples=[trainset[i][0] for i in idx]\n",
    "\n",
    "    testset_mal = MyBackdoorDataset(testset,targetclass,1, attack_names=[backdoor_name],p_size=trigger_size,mal_only=True)\n",
    "    test_loader_clean = torch.utils.data.DataLoader(testset, batch_size=1,shuffle=True)\n",
    "    test_loader_mal = torch.utils.data.DataLoader(testset_mal, batch_size=1,shuffle=True)\n",
    "    \n",
    "    \n",
    "    if 'natural' in backdoor_name:\n",
    "        save_path = './my_models/naive_%s.model'%task\n",
    "    else:\n",
    "        save_path = './my_models/%soriginal_trajoned_%s_targetclass_%s_%s.model'%(prefix,backdoor_name,str(targetclass),task)\n",
    "    \n",
    "    \n",
    "    model=Model(gpu=True,num_class=class_num)     \n",
    "    model=model.cuda()\n",
    "    model.load_state_dict(torch.load(save_path))\n",
    "    model = model.eval()\n",
    "    \n",
    "    \n",
    "    \n",
    "    detection=np.zeros((2,N))\n",
    "    for T,loader in enumerate([test_loader_clean,test_loader_mal]): \n",
    "        total=0\n",
    "        for data,y in loader:\n",
    "            if total%500==0 and total<N:\n",
    "                print(total)\n",
    "            if total>=N: break\n",
    "            data=data.cuda()\n",
    "            pred=model.forward(data)\n",
    "            pred=pred.max(1)[1].cpu()\n",
    "            if pred==y and total<N:\n",
    "                detection[T,total]=test_model(model,data,y,test_samples)\n",
    "                total+=1\n",
    "           \n",
    "    fpr=np.sum([1 for i in detection[0,:] if i>=0.5])/N\n",
    "    tnr= 1-fpr\n",
    "    tpr=np.sum([1 for i in detection[1,:] if i>=0.5])/N\n",
    "    fnr=1-tpr\n",
    "    # print(' STRIP test  FNR: %4f, TPR: %4f, FPR: %4f, TNR: %4f'  %(fnr,tpr,fpr,tnr))\n",
    "    # print(' %.2f /%.2f/-  '%((tpr+tnr)/2*100, fnr*100 )) \n",
    "    \n",
    "    return (tpr+tnr)/2,fpr, fnr, detection \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1bd39e58-d8c1-438f-8141-b4ffa1a93826",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_cleanse_up(task, targetclass, num_epochs=30):\n",
    "    \"\"\"\n",
    "    A simplified version of Neural Cleanse based on the description in the paper (without the complicated early stopping logic).\n",
    "\n",
    "    :param net: input network\n",
    "    :param loader: data loader with clean inputs for optimizing masks and patterns (training set or val set)\n",
    "    :param num_labels: number of labels for all-to-one search\n",
    "    \"\"\"\n",
    "    if os.path.exists('results/natural_%s.npy'%task):\n",
    "        return 0\n",
    "    BATCH_SIZE, _, trainset, testset,  Model, class_num = load_dataset_setting(task)\n",
    "    save_path = './my_models/naive_%s.model'%task\n",
    "    net = Model(gpu=True, num_class=class_num)\n",
    "    net.cuda()\n",
    "    print(save_path,class_num )\n",
    "    net.load_state_dict(torch.load(save_path))\n",
    "    # input_shape = loader.dataset[0][0].shape\n",
    "    \n",
    "    final_reg_vals = []\n",
    "    final_masks = []\n",
    "    final_patterns = []\n",
    "    input_shape=trainset[0][0].shape\n",
    "    \n",
    "    loader=torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    for target_label in [targetclass]:\n",
    "        \n",
    "        gamma=0.001  \n",
    "        print('\\n\\n================== Label {} =================='.format(target_label))\n",
    "\n",
    "        mask = nn.Parameter(torch.zeros(1, 1, *input_shape[-2:]).cuda())\n",
    "        pattern = nn.Parameter(torch.zeros(1, *input_shape[-3:]).cuda())\n",
    "        \n",
    "        optimizer = torch.optim.Adam([mask, pattern], lr=0.1, weight_decay=0)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epochs * len(loader))\n",
    "        \n",
    "        loss_ema = np.inf\n",
    "        reg_ema = np.inf\n",
    "        acc_ema = np.inf\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            print('epoch', epoch)\n",
    "            for i, (bx, _) in enumerate(loader):\n",
    "                bx = bx.cuda()\n",
    "                by = torch.LongTensor([target_label]).cuda().repeat(bx.shape[0])\n",
    "                \n",
    "                masked_bx = ((1 - mask) * bx) + (mask * pattern)\n",
    "\n",
    "                logits = net(masked_bx)\n",
    "                loss = F.cross_entropy(logits, by)\n",
    "                acc = (logits.argmax(dim=-1) == by).float().mean()\n",
    "                reg = mask.norm(p=1)\n",
    "                loss_bp = loss +gamma * reg\n",
    "                \n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss_bp.backward(inputs=[mask, pattern])\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                \n",
    "                mask.data = mask.data.clamp(0, 1)\n",
    "                pattern.data = pattern.data.clamp(0, 1)\n",
    "            \n",
    "                loss_ema = loss.item() if loss_ema == np.inf else loss_ema * 0.95 + loss.item() * 0.05\n",
    "                acc_ema = acc.item() if acc_ema == np.inf else acc_ema * 0.95 + acc.item() * 0.05\n",
    "                reg_ema = reg.item() if reg_ema == np.inf else reg_ema * 0.95 + reg.item() * 0.05\n",
    "                \n",
    "                if i%10 == 0:\n",
    "                    print('Iter {} | Loss: {:.3f}, Acc: {:.3f}, Reg: {:.3f}'.format(\n",
    "                        i, loss_ema, acc_ema, reg_ema))\n",
    "            if acc_ema >= 0.98 or gamma<0.0000001:\n",
    "                break\n",
    "            if acc_ema <= 0.2 and epoch%3==0:\n",
    "                gamma=gamma/10\n",
    "                print('new gamma is ', gamma)\n",
    "        \n",
    "        final_reg_vals.append(mask.norm(p=1).item())\n",
    "        final_masks.append(mask.data.cpu().numpy())\n",
    "        final_patterns.append(pattern.data.cpu().numpy())\n",
    "        np.save('results/natural_%s_pattern_targetclass_%s.npy'%(task,str(int(target_label))), pattern.data.cpu().numpy())\n",
    "        np.save('results/natural_%s_mask_targetclass_%s.npy'%(task,str(int(target_label))), mask.data.cpu().numpy())\n",
    "\n",
    "\n",
    "    dict_uap={'final_reg_vals':final_reg_vals, 'final_masks': final_masks, 'final_patterns':final_patterns}\n",
    "    np.save('results/natural_%s.npy'%task,dict_uap)\n",
    "    \n",
    "    return final_reg_vals, final_masks, final_patterns\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15eac3bf-af88-4da7-bbeb-939f5fcdc232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install statsmodels\n",
    "import certify_red\n",
    "from certify_red import certify\n",
    "def Decision_Radius(task,targetclass,triggersize,prefix=''):\n",
    "    \n",
    "    dict_cert={'type':[], 'ACR_hard':[], 'ACR_soft':[], 'r_hard':[],'r_soft':[]}\n",
    "    BATCH_SIZE, N_EPOCH, trainset, testset,  Model, class_num = load_dataset_setting(task)\n",
    "    tot_num = len(trainset)\n",
    "    \n",
    "\n",
    "    # trainset_mal = MyBackdoorDataset(trainset,targetclass,p,p_size=trigger_size,attack_names=[attackname])\n",
    "    \n",
    "    test_loader_clean = torch.utils.data.DataLoader(testset, batch_size=1,shuffle=True)\n",
    "    \n",
    "    N=200\n",
    "    gpu=False\n",
    "    if not torch.cuda.is_available():\n",
    "        quit()\n",
    "        \n",
    "    # Measure cleans\n",
    "    save_path_clean = './my_models/naive_%s.model'%task\n",
    "    model=Model(gpu=gpu,num_class=class_num)\n",
    "    model.load_state_dict(torch.load(save_path_clean))\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    cleans_data=[]\n",
    "    if os.path.exists('results/certifiedrobustness_%s.npy'%task):\n",
    "        dict_cert=np.load('results/certifiedrobustness_%s.npy'%task,allow_pickle=True)\n",
    "        dict_cert=dict_cert.item()\n",
    "    for data,y in test_loader_clean:\n",
    "        pred= model(data.cuda()).max(1)[1].cpu()\n",
    "        if pred.eq(y): cleans_data.append((data, y))\n",
    "        if len(cleans_data)>=N: break\n",
    "    if 'clean' not in dict_cert['type']:\n",
    "        ACR_hard,ACR_soft,radius_hard, radius_soft=certify(model, 'cuda', cleans_data, [], class_num,\n",
    "                                                                        mode='both', start_img=0, num_img=len(cleans_data), \n",
    "                                                                       sigma=0.25, beta=16)\n",
    "        dict_cert['type'].append('clean')\n",
    "        dict_cert['ACR_hard'].append(ACR_hard)\n",
    "        dict_cert['ACR_soft'].append(ACR_soft)\n",
    "        dict_cert['r_hard'].append(radius_hard)\n",
    "        dict_cert['r_soft'].append(radius_soft) \n",
    "        print(\"==\"*10+' CLEAN CERTIFY RADIUS  '+\"==\"*10)\n",
    "        print(ACR_hard,ACR_soft)\n",
    "        np.save( 'results/certifiedrobustness_%s.npy'%task,dict_cert)\n",
    "    #Measure r-radius for all Backdoors\n",
    "    for attackname in ['badnets','blend', 'trojan_sq', 'trojan_wm','nature', 'l2_inv' ]:#'natural_'+task ,\n",
    "        targetclass= 39 if  task =='cifar100' and 'natural' in attackname  else 6\n",
    "        if attackname not in dict_cert['type']:\n",
    "            \n",
    "            testset_mal = MyBackdoorDataset(testset,targetclass,1, p_size=triggersize,attack_names=[attackname],mal_only=True)\n",
    "            test_loader_mal = torch.utils.data.DataLoader(testset_mal, batch_size=1, shuffle=True)\n",
    "            save_path_trojan = './my_models/%soriginal_trajoned_%s_targetclass_%s_%s.model'%(prefix,attackname,str(targetclass),task)\n",
    "            if not 'natural' in attackname:\n",
    "                model=Model(gpu=gpu,num_class=class_num)\n",
    "                model.load_state_dict(torch.load(save_path_trojan))\n",
    "                model.cuda()\n",
    "                model.eval()\n",
    "                model.load_state_dict(torch.load(save_path_trojan))\n",
    "                model.eval()\n",
    "\n",
    "\n",
    "\n",
    "            Trojans_data=[]\n",
    "\n",
    "            for data,y in test_loader_mal:\n",
    "                pred= model(data.cuda()).max(1)[1].cpu()\n",
    "                if pred.eq(y) : Trojans_data.append((data, y))\n",
    "                if len(Trojans_data)>=N: break\n",
    "            ACR_hard,ACR_soft,radius_hard, radius_soft=certify(model, 'cuda', Trojans_data, [], class_num,\n",
    "                                                                        mode='both', start_img=0, num_img=len(cleans_data), \n",
    "                                                                       sigma=0.25, beta=16)\n",
    "            dict_cert['type'].append(attackname)\n",
    "            dict_cert['ACR_hard'].append(ACR_hard)\n",
    "            dict_cert['ACR_soft'].append(ACR_soft)\n",
    "            dict_cert['r_hard'].append(radius_hard)\n",
    "            dict_cert['r_soft'].append(radius_soft) \n",
    "            print(\"==\"*10+  attackname+ ' CERTIFY RADIUS  '+\"==\"*10)\n",
    "            print(attackname,ACR_hard,ACR_soft)\n",
    "            np.save( 'results/certifiedrobustness_%s.npy'%task,dict_cert)\n",
    "    np.save('results/certifiedrobustness_%s.npy'%task,dict_cert)\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6cfa794-09c3-4f41-b256-bec02aede4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def outliers_detection(clean,trojan,t_tnr=0.85,figname='test',label=None):\n",
    "    \n",
    "    clean=np.random.permutation(clean)\n",
    "    trojan=np.random.permutation(trojan)\n",
    "    \n",
    "    clean = [i if i != None else 10000 for i in clean]\n",
    "    trojan = [i if i != None else 10000 for i in trojan]\n",
    "    N=int(len(clean)/2)\n",
    "    \n",
    "    clean_1= clean[:N]\n",
    "    clean_1.sort()\n",
    "    idx=int(t_tnr*N+1)\n",
    "    upper_threshold= clean_1[idx]\n",
    "    # lower_threshold = clean_1[30]\n",
    "    while upper_threshold>5:\n",
    "        idx-=1\n",
    "        upper_threshold= clean_1[idx]\n",
    "    \n",
    "    \n",
    "    y=[1]*len(clean)+[2]*len(trojan)\n",
    "    all_delta= clean+trojan\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y, all_delta ,pos_label=2)\n",
    "    \n",
    "    auc= metrics.auc(fpr, tpr)\n",
    "    if not label is None:\n",
    "        for k in range(1,len(fpr)-1):\n",
    "            x=np.arange(fpr[k],fpr[k+1],0.05)\n",
    "            if len(x)>0 :\n",
    "                y=[tpr[k]]*len(x)\n",
    "                fpr=list(fpr)+list(x)\n",
    "                tpr=list(tpr)+y\n",
    "            \n",
    "        d={'True Positve Rate':tpr, 'False Positve Rate':fpr}\n",
    "        pdnumsqr = pd.DataFrame(d)\n",
    "        sns.set(style='darkgrid')\n",
    "        labels={'badnets': 'BadNets', 'nature':'Nature', 'blend':'Blend', 'l2_inv':'L2 inv', 'trojan_sq':'Trojan SQ', 'trojan_wm':'Trojan WM'}\n",
    "        swarm_plot =sns.lineplot(x='False Positve Rate', y='True Positve Rate', data=pdnumsqr, label=labels[label])\n",
    "        plt.legend(loc='lower right')\n",
    "        fig = swarm_plot.get_figure()\n",
    "        print(\"figs2/%s.pdf\"%figname)\n",
    "        fig.savefig(\"figs2/%s.pdf\"%figname) \n",
    "    fpr_list=[i for i in clean[N:] if i>upper_threshold ]#or i< lower_threshold\n",
    "    tpr_list=[i for i in trojan if i>upper_threshold]#or i< lower_threshold\n",
    "    fpr = len(fpr_list)/len(clean[N:])\n",
    "    tpr = len(tpr_list)/len(trojan)\n",
    "              \n",
    "    tnr = 1- fpr\n",
    "    fnr = 1- tpr\n",
    "\n",
    "    return (tnr+tpr)/2,fpr,fnr,auc\n",
    "\n",
    "def evaluate_model(task,backdoor_name,targetclass,trigger_size,prefix=''):\n",
    "    BATCH_SIZE, N_EPOCH, trainset, testset,  Model, class_num = load_dataset_setting(task)\n",
    "    tot_num = len(trainset)\n",
    "\n",
    "    testset_mal = MyBackdoorDataset(testset,targetclass,1, p_size=trigger_size,mal_only=True,attack_names=[backdoor_name])\n",
    "    test_loader_clean = torch.utils.data.DataLoader(testset, batch_size=64,shuffle=True)\n",
    "    test_loader_mal = torch.utils.data.DataLoader(testset_mal, batch_size=64,shuffle=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if 'natural' in backdoor_name:\n",
    "        save_path = './my_models/naive_%s.model'%task\n",
    "    else:\n",
    "        save_path = './my_models/%soriginal_trajoned_%s_targetclass_%s_%s.model'%(prefix,backdoor_name,str(targetclass),task)\n",
    "    \n",
    "    \n",
    "    model=Model(gpu=True,num_class=class_num)\n",
    "    model=model.cuda()\n",
    "    model.load_state_dict(torch.load(save_path))\n",
    "    model = model.eval()\n",
    "    \n",
    "    \n",
    "    acc_clean=eval_model(model, test_loader_clean, gpu=True)\n",
    "    acc_troj=eval_model(model, test_loader_mal, gpu=True)\n",
    "    \n",
    "    # print('Acc on clean samples : %.2f  Acc on Ttroj samples : %.2f'%(acc_clean*100,acc_troj*100))\n",
    "    return acc_clean, acc_troj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e135bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#blend, nature, , l2_inv, trojan_sq, trojan_vm\n",
    "#https://arxiv.org/pdf/1902.07623.pdf\n",
    "#https://adversarial-robustness-toolbox.readthedocs.io/en/latest/\n",
    "# !pip install adversarial-robustness-toolbox\n",
    "if not torch.cuda.is_available():\n",
    "    print('No GPU')\n",
    "    quit()\n",
    "\n",
    "def Train_all_models(robust=False, epsilon=None, TrainanyWay=False):\n",
    "    perturbationratio=0.1\n",
    "    for task in ['cifar10'  ]:#'cifar100','EuroSAT','gtsrb','flower' ,\n",
    "        train_naive_Model(task,TrainanyWay=False)\n",
    "        torch.cuda.empty_cache()\n",
    "        for backdoor_type in [ 'badnets','blend']:#,'nature','trojan_sq','trojan_wm', 'l2_inv','natural_'+task\n",
    "            targetclass = 6 \n",
    "            if 'natural' in backdoor_type and 'cifar10' in task:\n",
    "                targetclass= 1 if task=='cifar10' else 39\n",
    "            if robust:\n",
    "                train_traditional_backdoor_Model(task,perturbationratio, targetclass,backdoor_type,TrainanyWay=TrainanyWay, Robustness=True, epsilon=epsilon)\n",
    "            else:\n",
    "                train_traditional_backdoor_Model(task,perturbationratio, targetclass,backdoor_type,TrainanyWay=TrainanyWay)\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "def evaluate_all_models(prefix=''):\n",
    "    text=''\n",
    "    for task in ['cifar10']:#'cifar100', 'cifar10','gtsrb','svhn','flower' \n",
    "        text+= task+'  '\n",
    "        for backdoor_name in [ 'badnets','blend','nature','trojan_sq','trojan_wm', 'l2_inv'  ]:#,'natural_'+task\n",
    "            targetclass = 6 \n",
    "            if 'natural' in backdoor_name and 'cifar10' in task:\n",
    "                targetclass= 1 if task=='cifar10' else 39\n",
    "           \n",
    "            acc_clean, acc_troj = evaluate_model(task,backdoor_name,targetclass,4,prefix)\n",
    "            \n",
    "            text+= '& %.2f &  %.2f '%( acc_clean*100, acc_troj*100)\n",
    "            print(text)\n",
    "            torch.cuda.empty_cache()\n",
    "        text+='\\n'\n",
    "\n",
    "    print(text)\n",
    "    return text\n",
    "    \n",
    "def STRIP_evaluation(t_tnr):\n",
    "    text='STIP & Strip+\\n'\n",
    "    triggersize=4\n",
    "    targetclass=6\n",
    "    for task in ['flower' ]:#'svhn' ,'gtsrb','cifar10','cifar100','gtsrb','cifar10'\n",
    "        text+= task + '\\n'\n",
    "        for backdoor_name in [ 'badnets','blend','nature','trojan_sq','trojan_wm', 'l2_inv'  ]:#,'natural_'+task\n",
    "            text+=backdoor_name\n",
    "            DR, FPR, FNR, detection=STRIP(task,triggersize,backdoor_name,targetclass)\n",
    "            text+='%.2f/%.2f/%.2f'%((1-FNR)*100,FPR*100, (1-FNR)*(1-FPR)*2/ (2-FNR-FPR))\n",
    "            figname=task+'_strip'#, figname=figname, label=backdoor_name\n",
    "            DR, FPR, FNR, AUC =outliers_detection(detection[0,:],detection[1,:], figname=figname, label=backdoor_name)\n",
    "            text+=' & %.2f/%.2f/%.2f \\n'%((1-FNR)*100,FPR*100, (1-FNR)*(1-FPR)*2/ (2-FNR-FPR))\n",
    "            torch.cuda.empty_cache()\n",
    "    print(text)\n",
    "    \n",
    "            \n",
    "def ABC_evauation(t_tnr,prefix=''):\n",
    "    triggersize=4\n",
    "    text=''\n",
    "    for task in  ['cifar10' ]:#'svhn' ,'gtsrb','cifar10','cifar100','flower','cifar10',\n",
    "        text+= task+'  '\n",
    "        for backdoor_name in ['badnets','blend','nature','trojan_sq','trojan_wm', 'l2_inv']:# 'badnets','blend','nature','trojan_sq','trojan_wm', 'l2_inv','natural_'+task\n",
    "            text+=backdoor_name+'\\n'\n",
    "            for advAttack in ['DeepFool']:#blackbox','blackbox','FGSM','IFGSM'\n",
    "                targetclass = 6 \n",
    "                if 'natural' in backdoor_name and 'cifar10' in task:\n",
    "                    targetclass= 1 if task=='cifar10' else 39\n",
    "                RobustnessAnalysys(task,advAttack,targetclass,triggersize,backdoor_name,prefix)\n",
    "                dict_adv=np.load('./results/%s%s_%s_%s.npy'%(prefix,advAttack,task,backdoor_name),allow_pickle=True)\n",
    "                dict_adv = dict_adv.item()\n",
    "                delta=np.array(dict_adv['delta'])\n",
    "                Trojaned=np.array(dict_adv['Trojaned'])\n",
    "                success=np.array(dict_adv['success'])\n",
    "                hyperP= np.array(dict_adv['hyperP'])\n",
    "                idx_clean=np.where(Trojaned==0)[0]\n",
    "                idx_trojan=np.where(Trojaned==1)[0]\n",
    "                idx_success=np.where(success==1)[0]\n",
    "                trojan_success=[i for i in idx_success if i in idx_trojan]\n",
    "                figname=task+'_'+advAttack#, figname=figname, label=backdoor_name\n",
    "                print(figname)\n",
    "                DR, FPR, FNR, AUC = outliers_detection(delta[idx_clean],delta[idx_trojan],t_tnr=t_tnr,figname=figname, label=backdoor_name)\n",
    "                text+='&  %.2f/%.2f/%.2f'%((1-FNR)*100,FPR*100, (1-FNR)*(1-FPR)*2/ (2-FNR-FPR))\n",
    "                torch.cuda.empty_cache()\n",
    "            text+= '\\n'\n",
    "    print(text)\n",
    "    \n",
    "    \n",
    "# Train_all_models()\n",
    "\n",
    "# evaluate_all_models()\n",
    "# ABC_evauation(0.85)\n",
    "# STRIP_evaluation(0.85)\n",
    "# Decision_Radius('flower',6,4)\n",
    "#& 85.58 &  97.35 & 85.80 &  100.00 & 85.59 &  100.00\n",
    "# cifar10  & 83.81 &  96.20 & 83.65 &  100.00\n",
    "# for eps in [ 0.001]:\n",
    "#     Train_all_models(robust=True, epsilon=eps,  TrainanyWay=True)\n",
    "#     ABC_evauation(0.85, prefix='robust_eps_%.4f_'%eps)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10f24387-6dbc-4233-90b1-32dcf624c8e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/cluster/envs/templates/pytorch-1.11/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "295de10e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "| Wide-Resnet 22x10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m model\u001b[38;5;241m=\u001b[39mModel(gpu\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,num_class\u001b[38;5;241m=\u001b[39mclass_num)\n\u001b[1;32m      7\u001b[0m model\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m----> 8\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN_EPOCH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mRobustness\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m ABC_evauation(\u001b[38;5;241m0.85\u001b[39m,prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrobust_eps_\u001b[39m\u001b[38;5;132;01m%.4f\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m%\u001b[39meps)\n",
      "Cell \u001b[0;32mIn[6], line 55\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloader, epoch_num, gpu, verbose, Robustness, epsilon)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     adversary\u001b[38;5;241m=\u001b[39mLinfPGDAttack(model)\n\u001b[0;32m---> 55\u001b[0m adv\u001b[38;5;241m=\u001b[39m\u001b[43madversary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperturb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_in\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m pred \u001b[38;5;241m=\u001b[39m model(adv)\n\u001b[1;32m     57\u001b[0m loss\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mloss(pred, y_in)\n",
      "Cell \u001b[0;32mIn[6], line 17\u001b[0m, in \u001b[0;36mLinfPGDAttack.perturb\u001b[0;34m(self, x_natural, y)\u001b[0m\n\u001b[1;32m     15\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(x)\n\u001b[1;32m     16\u001b[0m     loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(logits, y)\n\u001b[0;32m---> 17\u001b[0m grad \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     18\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39msign(grad\u001b[38;5;241m.\u001b[39mdetach())\n\u001b[1;32m     19\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmin(torch\u001b[38;5;241m.\u001b[39mmax(x, x_natural \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon), x_natural \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon)\n",
      "File \u001b[0;32m/mnt/cluster/envs/users/arezoo/pytorch-1.11-n/lib/python3.9/site-packages/torch/autograd/__init__.py:303\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched)\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _vmap_internals\u001b[38;5;241m.\u001b[39m_vmap(vjp, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, allow_none_pass_through\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(grad_outputs_)\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for eps in [  0.1,0.01]:\n",
    "    BATCH_SIZE, N_EPOCH, trainset, testset,  Model, class_num = load_dataset_setting('cifar10')\n",
    "    tot_num = len(trainset)\n",
    "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(testset, batch_size=1)\n",
    "    model=Model(gpu=True,num_class=class_num)\n",
    "    model=model.cuda()\n",
    "    train_model(model, train_loader, N_EPOCH, gpu=True,verbose=True, Robustness=True, epsilon=eps)\n",
    "    ABC_evauation(0.85,prefix='robust_eps_%.4f_'%eps)\n",
    "# BATCH_SIZE, N_EPOCH, trainset, testset,  Model, class_num = load_dataset_setting('gtsrb')\n",
    "# train,test=[],[]\n",
    "# for x,y in trainset:\n",
    "#     train.append(x.cpu().numpy().transpose(1,2,0))\n",
    "# for x,y in testset:\n",
    "#     test.append(x.cpu().numpy().transpose(1,2,0))\n",
    "# np.save('gtsrb.npy', {'train': train, 'test':test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e75ce3b5-0bc2-4549-9c7f-986b93c2201f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "| Wide-Resnet 22x10\n",
      "cifar10  & 79.23 &  96.03 \n",
      "Files already downloaded and verified\n",
      "| Wide-Resnet 22x10\n",
      "cifar10  & 79.23 &  96.03 & 80.19 &  99.88 \n",
      "Files already downloaded and verified\n",
      "| Wide-Resnet 22x10\n",
      "cifar10  & 79.23 &  96.03 & 80.19 &  99.88 & 80.00 &  100.00 \n",
      "Files already downloaded and verified\n",
      "| Wide-Resnet 22x10\n",
      "cifar10  & 79.23 &  96.03 & 80.19 &  99.88 & 80.00 &  100.00 & 80.06 &  100.00 \n",
      "Files already downloaded and verified\n",
      "| Wide-Resnet 22x10\n",
      "cifar10  & 79.23 &  96.03 & 80.19 &  99.88 & 80.00 &  100.00 & 80.06 &  100.00 & 79.81 &  100.00 \n",
      "Files already downloaded and verified\n",
      "| Wide-Resnet 22x10\n",
      "cifar10  & 79.23 &  96.03 & 80.19 &  99.88 & 80.00 &  100.00 & 80.06 &  100.00 & 79.81 &  100.00 & 80.47 &  99.98 \n",
      "cifar10  & 79.23 &  96.03 & 80.19 &  99.88 & 80.00 &  100.00 & 80.06 &  100.00 & 79.81 &  100.00 & 80.47 &  99.98 \n",
      "\n",
      "Files already downloaded and verified\n",
      "| Wide-Resnet 22x10\n",
      "cifar10  & 36.35 &  53.74 \n",
      "Files already downloaded and verified\n",
      "| Wide-Resnet 22x10\n",
      "cifar10  & 36.35 &  53.74 & 40.25 &  86.88 \n",
      "Files already downloaded and verified\n",
      "| Wide-Resnet 22x10\n",
      "cifar10  & 36.35 &  53.74 & 40.25 &  86.88 & 40.32 &  100.00 \n",
      "Files already downloaded and verified\n",
      "| Wide-Resnet 22x10\n",
      "cifar10  & 36.35 &  53.74 & 40.25 &  86.88 & 40.32 &  100.00 & 33.62 &  100.00 \n",
      "Files already downloaded and verified\n",
      "| Wide-Resnet 22x10\n",
      "cifar10  & 36.35 &  53.74 & 40.25 &  86.88 & 40.32 &  100.00 & 33.62 &  100.00 & 26.51 &  100.00 \n",
      "Files already downloaded and verified\n",
      "| Wide-Resnet 22x10\n",
      "cifar10  & 36.35 &  53.74 & 40.25 &  86.88 & 40.32 &  100.00 & 33.62 &  100.00 & 26.51 &  100.00 & 35.28 &  51.90 \n",
      "cifar10  & 36.35 &  53.74 & 40.25 &  86.88 & 40.32 &  100.00 & 33.62 &  100.00 & 26.51 &  100.00 & 35.28 &  51.90 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for eps in [ 0.01, 0.1]:\n",
    "    evaluate_all_models(prefix='robust_eps_%.4f_'%eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4925133d-77f2-4ae3-89e4-8cf284a2e363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "| Wide-Resnet 22x10\n",
      "| Wide-Resnet 22x10\n",
      "../aten/src/ATen/native/cuda/Loss.cu:257: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [9,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/cluster/data/users/arezoo/SP/trainmodels.py\", line 199, in <module>\n",
      "    Train_all_models()\n",
      "  File \"/mnt/cluster/data/users/arezoo/SP/trainmodels.py\", line 181, in Train_all_models\n",
      "    train_naive_Model(task,TrainanyWay=False)\n",
      "  File \"/mnt/cluster/data/users/arezoo/SP/trainmodels.py\", line 117, in train_naive_Model\n",
      "    train_model(model, train_loader, epoch_num=N_EPOCH,gpu=gpu, verbose=True)\n",
      "  File \"/mnt/cluster/data/users/arezoo/SP/trainmodels.py\", line 88, in train_model\n",
      "    cum_loss += loss.item() * B\n",
      "RuntimeError: CUDA error: device-side assert triggered\n",
      "CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "!python trainmodels.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d271b31-ea1a-4a6a-939d-30d2f321e66e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch-1.11-n]",
   "language": "python",
   "name": "conda-env-pytorch-1.11-n-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
